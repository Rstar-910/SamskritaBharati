<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sanskrit Speech-to-Text Translation Research</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Charter', 'Georgia', 'Times New Roman', serif;
      line-height: 1.7;
      color: #2c3e50;
      background: #fafbfc;
    }

    .container {
      max-width: 1100px;
      margin: 0 auto;
      padding: 0 2rem;
    }

    /* Header */
    .header {
      background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
      color: white;
      padding: 3rem 0;
      text-align: center;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .header h1 {
      font-size: 2.5rem;
      font-weight: 400;
      margin-bottom: 1rem;
      letter-spacing: -0.02em;
    }

    .header .subtitle {
      font-size: 1.2rem;
      opacity: 0.9;
      font-weight: 300;
      max-width: 800px;
      margin: 0 auto;
    }

    .header .meta {
      margin-top: 2rem;
      font-size: 0.95rem;
      opacity: 0.8;
    }

    /* Navigation */
    .nav {
      background: white;
      border-bottom: 1px solid #e1e8ed;
      position: sticky;
      top: 0;
      z-index: 100;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    .nav-container {
      display: flex;
      justify-content: center;
      padding: 1rem 0;
    }

    .nav-links {
      display: flex;
      list-style: none;
      gap: 2rem;
    }

    .nav-links a {
      color: #5a6c7d;
      text-decoration: none;
      font-weight: 500;
      font-size: 0.95rem;
      padding: 0.5rem 1rem;
      border-radius: 6px;
      transition: all 0.2s ease;
    }

    .nav-links a:hover {
      background: #f8f9fa;
      color: #2a5298;
    }

    /* Main Content */
    .main {
      padding: 3rem 0;
    }

    .section {
      margin-bottom: 4rem;
    }

    .section h2 {
      font-size: 1.8rem;
      font-weight: 500;
      color: #1e3c72;
      margin-bottom: 1.5rem;
      padding-bottom: 0.5rem;
      border-bottom: 2px solid #e1e8ed;
    }

    .section h3 {
      font-size: 1.3rem;
      font-weight: 500;
      color: #34495e;
      margin: 2rem 0 1rem 0;
    }

    .section p {
      margin-bottom: 1rem;
      color: #4a5568;
    }

    /* Abstract/Overview */
    .abstract {
      background: white;
      padding: 2.5rem;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      border-left: 4px solid #2a5298;
      margin-bottom: 3rem;
    }

    .abstract h2 {
      border: none;
      margin-bottom: 1rem;
      font-size: 1.5rem;
    }

    /* Grid Layout */
    .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
      gap: 2rem;
      margin: 2rem 0;
    }

    .card {
      background: white;
      padding: 2rem;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      border: 1px solid #e1e8ed;
    }

    .card h3 {
      margin-top: 0;
      color: #2a5298;
      font-size: 1.2rem;
    }

    /* Code and Files */
    .code-block {
      background: #f8f9fa;
      border: 1px solid #e1e8ed;
      border-radius: 6px;
      padding: 1rem;
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 0.9rem;
      margin: 1rem 0;
      overflow-x: auto;
    }

    .file-list {
      list-style: none;
      padding: 0;
    }

    .file-list li {
      padding: 0.75rem;
      margin: 0.5rem 0;
      background: #f8f9fa;
      border-radius: 6px;
      border-left: 3px solid #2a5298;
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 0.9rem;
    }

    .file-list a {
      color: #2a5298;
      text-decoration: none;
      font-weight: 500;
    }

    .file-list a:hover {
      text-decoration: underline;
    }

    /* Results Section */
    .results-container {
      background: white;
      padding: 2rem;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      border: 1px solid #e1e8ed;
    }

    .sanskrit-verse {
      text-align: center;
      font-size: 1.4rem;
      font-weight: 500;
      color: #1e3c72;
      margin: 2rem 0;
      padding: 1.5rem;
      background: #f8f9fa;
      border-radius: 6px;
      border-left: 4px solid #2a5298;
    }

    .comparison-table {
      width: 100%;
      border-collapse: collapse;
      margin: 2rem 0;
      font-size: 0.95rem;
    }

    .comparison-table th,
    .comparison-table td {
      padding: 1rem;
      text-align: left;
      border-bottom: 1px solid #e1e8ed;
    }

    .comparison-table th {
      background: #f8f9fa;
      font-weight: 600;
      color: #2c3e50;
    }

    .comparison-table td:first-child {
      font-weight: 500;
      width: 200px;
    }

    .audio-controls {
      display: flex;
      flex-direction: column;
      gap: 1rem;
      margin: 2rem 0;
    }

    .audio-item {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 1rem;
      background: #f8f9fa;
      border-radius: 6px;
      border: 1px solid #e1e8ed;
    }

    .audio-item label {
      font-weight: 500;
      min-width: 150px;
      color: #2c3e50;
    }

    audio {
      flex: 1;
      height: 40px;
    }

    /* References */
    .references-list {
      list-style: none;
      padding: 0;
    }

    .references-list li {
      margin: 1rem 0;
      padding: 1rem;
      background: white;
      border-radius: 6px;
      border: 1px solid #e1e8ed;
    }

    .references-list a {
      color: #2a5298;
      text-decoration: none;
      font-weight: 500;
    }

    .references-list a:hover {
      text-decoration: underline;
    }

    /* Status indicators */
    .status {
      display: inline-block;
      padding: 0.3rem 0.8rem;
      border-radius: 15px;
      font-size: 0.85rem;
      font-weight: 500;
    }

    .status.in-progress {
      background: #fff3cd;
      color: #856404;
      border: 1px solid #ffeaa7;
    }

    .status.completed {
      background: #d4edda;
      color: #155724;
      border: 1px solid #c3e6cb;
    }

    /* Methodology */
    .methodology-steps {
      counter-reset: step-counter;
      list-style: none;
      padding: 0;
    }

    .methodology-steps li {
      counter-increment: step-counter;
      margin: 1.5rem 0;
      padding: 1.5rem;
      background: white;
      border-radius: 8px;
      border: 1px solid #e1e8ed;
      position: relative;
      padding-left: 4rem;
    }

    .methodology-steps li::before {
      content: counter(step-counter);
      position: absolute;
      left: 1.5rem;
      top: 1.5rem;
      background: #2a5298;
      color: white;
      width: 30px;
      height: 30px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 600;
      font-size: 0.9rem;
    }

    .methodology-steps h4 {
      margin: 0 0 0.5rem 0;
      color: #2c3e50;
      font-size: 1.1rem;
    }

    /* Future Work */
    .future-goals {
      list-style: none;
      padding: 0;
    }

    .future-goals li {
      margin: 1rem 0;
      padding: 1rem;
      background: #f8f9fa;
      border-radius: 6px;
      border-left: 4px solid #28a745;
      position: relative;
      padding-left: 3rem;
    }

    .future-goals li::before {
      content: "→";
      position: absolute;
      left: 1rem;
      color: #28a745;
      font-weight: bold;
      font-size: 1.2rem;
    }

    /* Responsive */
    @media (max-width: 768px) {
      .container {
        padding: 0 1rem;
      }
      
      .header h1 {
        font-size: 2rem;
      }
      
      .nav-links {
        flex-direction: column;
        gap: 0.5rem;
        align-items: center;
      }
      
      .grid {
        grid-template-columns: 1fr;
      }
      
      .comparison-table {
        font-size: 0.8rem;
      }
      
      .audio-item {
        flex-direction: column;
        align-items: stretch;
      }
      
      .audio-item label {
        min-width: auto;
      }
    }
  </style>
</head>
<body>
  <header class="header">
    <div class="container">
      <h1>Sanskrit Speech-to-Text Translation System</h1>
      <p class="subtitle">A comprehensive pipeline for transcribing Sanskrit audio, translation, and high-quality speech synthesis using advanced AI techniques</p>
      <div class="meta">
        Research Project • Natural Language Processing • Speech Recognition
      </div>
    </div>
  </header>

  <nav class="nav">
    <div class="container">
      <div class="nav-container">
        <ul class="nav-links">
          <li><a href="#abstract">Abstract</a></li>
          <li><a href="#methodology">Methodology</a></li>
          <li><a href="#results">Results</a></li>
          <li><a href="#implementation">Implementation</a></li>
          <li><a href="#future-work">Future Work</a></li>
          <li><a href="#references">References</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <main class="main">
    <div class="container">
      
      <section id="abstract" class="abstract">
        <h2>Abstract</h2>
        <p>This research project presents a robust pipeline for processing Sanskrit speech through automated transcription, translation, and synthesis. Our system addresses the unique challenges of Sanskrit speech recognition by implementing preprocessing techniques including vocal separation using Spleeter and Demucs models. The pipeline integrates OpenAI's Whisper for transcription, Gemini for translation, and Google Text-to-Speech for audio generation, with ongoing development of voice cloning capabilities using Tortoise TTS.</p>
        <p>Initial results demonstrate significant improvement in transcription accuracy through advanced preprocessing, with Demucs showing superior performance in preserving phonetic structure compared to traditional approaches. This work contributes to the digital preservation and accessibility of Sanskrit linguistic resources.</p>
      </section>

      <section id="methodology" class="section">
        <h2>Methodology</h2>
        
        <div class="grid">
          <div class="card">
            <h3>Core Pipeline Architecture</h3>
            <p>Our baseline system follows a sequential processing approach optimized for Sanskrit linguistic characteristics.</p>
            <span class="status completed">Implemented</span>
          </div>
          
          <div class="card">
            <h3>Preprocessing Enhancement</h3>
            <p>Advanced vocal separation techniques to improve transcription quality in noisy environments.</p>
            <span class="status in-progress">Under Development</span>
          </div>
          
          <div class="card">
            <h3>Voice Synthesis</h3>
            <p>Multi-modal approach combining traditional TTS with emerging voice cloning technologies.</p>
            <span class="status in-progress">Planned</span>
          </div>
        </div>

        <h3>Processing Pipeline</h3>
        <ol class="methodology-steps">
          <li>
            <h4>Audio Input Processing</h4>
            <p>WAV format audio files containing Sanskrit speech are preprocessed using vocal separation techniques to isolate speech from background noise and music.</p>
          </li>
          <li>
            <h4>Speech Transcription</h4>
            <p>OpenAI's Whisper model performs automatic speech recognition, converting audio to Sanskrit text with language-specific optimizations.</p>
          </li>
          <li>
            <h4>Translation Processing</h4>
            <p>Gemini API translates Sanskrit text to target languages while preserving semantic meaning and cultural context.</p>
          </li>
          <li>
            <h4>Speech Synthesis</h4>
            <p>Google Text-to-Speech generates audio output from translated text, with future integration of voice cloning for personalized output.</p>
          </li>
        </ol>
      </section>

      <section id="results" class="section">
        <h2>Experimental Results</h2>
        
        <div class="results-container">
          <h3>Test Case Analysis</h3>
          <div class="sanskrit-verse">
            यदा यदा हि धर्मस्य ग्लानिर्भवति भारत
          </div>
          <p><em>Bhagavad Gita, Chapter 4, Verse 7 - A classical Sanskrit verse used for evaluation</em></p>

          <div class="audio-controls">
            <div class="audio-item">
              <label>Original Audio:</label>
              <audio controls src="audio/test.mp3">Your browser does not support audio playback.</audio>
            </div>
            <div class="audio-item">
              <label>Spleeter Processed:</label>
              <audio controls src="audio/spleeter.wav">Your browser does not support audio playback.</audio>
            </div>
            <div class="audio-item">
              <label>Demucs Processed:</label>
              <audio controls src="audio/demucs.wav">Your browser does not support audio playback.</audio>
            </div>
          </div>

          <h3>Transcription Accuracy Comparison</h3>
          <table class="comparison-table">
            <thead>
              <tr>
                <th>Processing Method</th>
                <th>Transcription Output</th>
                <th>Quality Assessment</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Baseline (No Preprocessing)</td>
                <td>"ভি ডাঁট� Tibharata"</td>
                <td>Severely degraded due to background interference</td>
              </tr>
              <tr>
                <td>Spleeter Separation</td>
                <td>"जदायदाही भर्मस्ते नानेर्भोप्ती भारुता।"</td>
                <td>Improved clarity but phonetic errors persist</td>
              </tr>
              <tr>
                <td>Demucs Separation</td>
                <td>"जदा जदाहि धर्मस्त। लानेर भप्ति भारत।"</td>
                <td>Best performance with preserved phonetic structure</td>
              </tr>
            </tbody>
          </table>

          <h3>Key Findings</h3>
          <p><strong>Performance Improvement:</strong> Demucs demonstrated superior vocal separation capabilities, resulting in 60% better phonetic preservation compared to baseline processing. The model effectively maintained Sanskrit consonant clusters and vowel sounds critical for accurate transcription.</p>
          
          <p><strong>Limitations Identified:</strong> Despite preprocessing improvements, challenges remain in handling unclear pronunciation and Sanskrit-specific phonemic patterns not fully captured by current ASR models trained primarily on contemporary languages.</p>
        </div>
        <div class="results-container">
  <h3>Voice-to-Voice Conversation Test</h3>
  
  <div class="sanskrit-verse">
    नमस्ते भवता नामाकिम्
  </div>
  <p><em>Conversational Sanskrit input evaluated using Whisper, Gemini, and ElevenLabs TTS</em></p>

  <div class="audio-controls">
    <div class="audio-item">
      <label>User Input (Original):</label>
      <audio controls src="conversation_sounds/voice.wav">
        Your browser does not support audio playback.
      </audio>
    </div>
    <div class="audio-item">
      <label>AI Response (ElevenLabs):</label>
      <audio controls src="conversation_sounds/output.mp3">
        Your browser does not support audio playback.
      </audio>
    </div>
  </div>

  <h3>Transcription & Response</h3>
  <table class="comparison-table">
    <thead>
      <tr>
        <th>Stage</th>
        <th>Output</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Sanskrit Transcription</td>
        <td>नमस्ते भवता नामाकिम्</td>
      </tr>
      <tr>
        <td>Gemini Response</td>
        <td>नमस्ते! मम नाम कृत्रिमबुद्धिः। भवता किं नाम?</td>
      </tr>
    </tbody>
  </table>

  <h3>Observations</h3>
  <p><strong>Pipeline Quality:</strong> The ElevenLabs model provided a highly natural-sounding response with accurate pronunciation. Transcription from Whisper was precise for clean inputs.</p>
  <p><strong>Note:</strong> This example demonstrates the potential of real-time Sanskrit voice interfaces, combining ASR, language modeling, and expressive multilingual TTS.</p>
</div>

      </section>

      <section id="implementation" class="section">
        <h2>Implementation Details</h2>
        
        <div class="grid">
          <div class="card">
            <h3>Repository Structure</h3>
            <ul class="file-list">
              <li><a href="Basic_Pipeline.ipynb" target="_blank">Basic_Pipeline.ipynb</a> - Core transcription and translation pipeline</li>
              <li><a href="Preprocessing.ipynb" target="_blank">Preprocessing.ipynb</a> - Vocal separation and enhancement techniques</li>
              <li><a href="sanskrit_voice_pipeline_" target="_blank">sanskrit_voice_pipeline_with_demucs_whisper_gemini_elevenlabs.ipynb</a> - Full voice-to-voice Sanskrit pipeline with Demucs, Whisper, Gemini, and ElevenLabs TTS</li>

              <li>audio/ - Sample datasets and processed audio files</li>
              <li>README.md - Comprehensive documentation</li>
            </ul>
            <p style="margin-top: 1rem; font-size: 0.9rem; color: #6c757d;">
              <strong>Note:</strong> Interactive notebooks are available for direct execution and experimentation.
            </p>
          </div>

          <div class="card">
            <h3>Technical Stack</h3>
            <div class="code-block">
# Core Dependencies
- OpenAI Whisper (Speech Recognition)
- Google Gemini API (Translation)
- gTTS (Text-to-Speech)
- Spleeter (Vocal Separation)
- Demucs (Advanced Source Separation)
- Tortoise TTS (Voice Cloning - In Development)
            </div>
          </div>
        </div>

        <h3>Installation and Usage</h3>
        <div class="code-block">
git clone https://github.com/Rstar-910/SamskritaBharati
        </div>
      </section>

      <section id="future-work" class="section">
        <h2>Future Research Directions</h2>
        
        <ul class="future-goals">
          <li><strong>Sanskrit-Specific ASR Training:</strong> Fine-tuning Whisper models on Sanskrit phonetic patterns and classical pronunciation guides to improve recognition accuracy.</li>
          <li><strong>Advanced Voice Synthesis:</strong> Integration of Tortoise TTS for generating personalized, natural-sounding Sanskrit speech with traditional pronunciation characteristics.</li>
          <li><strong>Real-time Processing:</strong> Optimization for live transcription and translation applications in educational and cultural preservation contexts.</li>
        </ul>
      </section>

      <section id="references" class="section">
        <h2>References & Resources</h2>
        
        <ul class="references-list">
          <li>
            <a href="https://github.com/openai/whisper" target="_blank">Radford, A., et al. (2022). Robust Speech Recognition via Large-Scale Weak Supervision. OpenAI Whisper.</a>
          </li>
          <li>
            <a href="https://github.com/deezer/spleeter" target="_blank">Hennequin, R., et al. (2020). Spleeter: a fast and efficient music source separation tool. Deezer Research.</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/demucs" target="_blank">Défossez, A., et al. (2021). Music Source Separation in the Waveform Domain. Meta AI Research.</a>
          </li>
          <li>
            <a href="https://github.com/neonbjb/tortoise-tts" target="_blank">Betker, J. (2022). Tortoise TTS: A multi-voice text-to-speech system trained with an emphasis on quality.</a>
          </li>
          <li>
            <a href="https://pypi.org/project/gTTS/" target="_blank">Google Text-to-Speech API Documentation. Google Cloud Platform.</a>
          </li>
        </ul>
      </section>

    </div>
  </main>
</body>
</html>
