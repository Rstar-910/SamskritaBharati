<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sanskrit Speech-to-Text Translation Research</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Charter', 'Georgia', 'Times New Roman', serif;
      line-height: 1.7;
      color: #2c3e50;
      background: #fafbfc;
    }

    .container {
      max-width: 1100px;
      margin: 0 auto;
      padding: 0 2rem;
    }

    /* Header */
    .header {
      background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
      color: white;
      padding: 3rem 0;
      text-align: center;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .header h1 {
      font-size: 2.5rem;
      font-weight: 400;
      margin-bottom: 1rem;
      letter-spacing: -0.02em;
    }

    .header .subtitle {
      font-size: 1.2rem;
      opacity: 0.9;
      font-weight: 300;
      max-width: 800px;
      margin: 0 auto;
    }

    .header .meta {
      margin-top: 2rem;
      font-size: 0.95rem;
      opacity: 0.8;
    }

    /* Navigation */
    .nav {
      background: white;
      border-bottom: 1px solid #e1e8ed;
      position: sticky;
      top: 0;
      z-index: 100;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    .nav-container {
      display: flex;
      justify-content: center;
      padding: 1rem 0;
    }

    .nav-links {
      display: flex;
      list-style: none;
      gap: 2rem;
    }

    .nav-links a {
      color: #5a6c7d;
      text-decoration: none;
      font-weight: 500;
      font-size: 0.95rem;
      padding: 0.5rem 1rem;
      border-radius: 6px;
      transition: all 0.2s ease;
    }

    .nav-links a:hover {
      background: #f8f9fa;
      color: #2a5298;
    }

    /* Main Content */
    .main {
      padding: 3rem 0;
    }

    .section {
      margin-bottom: 4rem;
    }

    .section h2 {
      font-size: 1.8rem;
      font-weight: 500;
      color: #1e3c72;
      margin-bottom: 1.5rem;
      padding-bottom: 0.5rem;
      border-bottom: 2px solid #e1e8ed;
    }

    .section h3 {
      font-size: 1.3rem;
      font-weight: 500;
      color: #34495e;
      margin: 2rem 0 1rem 0;
    }

    .section p {
      margin-bottom: 1rem;
      color: #4a5568;
    }

    /* Abstract/Overview */
    .abstract {
      background: white;
      padding: 2.5rem;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      border-left: 4px solid #2a5298;
      margin-bottom: 3rem;
    }

    .abstract h2 {
      border: none;
      margin-bottom: 1rem;
      font-size: 1.5rem;
    }

    /* Grid Layout */
    .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
      gap: 2rem;
      margin: 2rem 0;
    }

    .card {
      background: white;
      padding: 2rem;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      border: 1px solid #e1e8ed;
    }

    .card h3 {
      margin-top: 0;
      color: #2a5298;
      font-size: 1.2rem;
    }

    /* Code and Files */
    .code-block {
      background: #f8f9fa;
      border: 1px solid #e1e8ed;
      border-radius: 6px;
      padding: 1rem;
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 0.9rem;
      margin: 1rem 0;
      overflow-x: auto;
    }

    .file-list {
      list-style: none;
      padding: 0;
    }

    .file-list li {
      padding: 0.75rem;
      margin: 0.5rem 0;
      background: #f8f9fa;
      border-radius: 6px;
      border-left: 3px solid #2a5298;
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 0.9rem;
    }

    .file-list a {
      color: #2a5298;
      text-decoration: none;
      font-weight: 500;
    }

    .file-list a:hover {
      text-decoration: underline;
    }

    /* Results Section */
    .results-container {
      background: white;
      padding: 2rem;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      border: 1px solid #e1e8ed;
    }

    .sanskrit-verse {
      text-align: center;
      font-size: 1.4rem;
      font-weight: 500;
      color: #1e3c72;
      margin: 2rem 0;
      padding: 1.5rem;
      background: #f8f9fa;
      border-radius: 6px;
      border-left: 4px solid #2a5298;
    }

    .comparison-table {
      width: 100%;
      border-collapse: collapse;
      margin: 2rem 0;
      font-size: 0.95rem;
    }

    .comparison-table th,
    .comparison-table td {
      padding: 1rem;
      text-align: left;
      border-bottom: 1px solid #e1e8ed;
    }

    .comparison-table th {
      background: #f8f9fa;
      font-weight: 600;
      color: #2c3e50;
    }

    .comparison-table td:first-child {
      font-weight: 500;
      width: 200px;
    }

    .audio-controls {
      display: flex;
      flex-direction: column;
      gap: 1rem;
      margin: 2rem 0;
    }

    .audio-item {
      display: flex;
      align-items: center;
      gap: 1rem;
      padding: 1rem;
      background: #f8f9fa;
      border-radius: 6px;
      border: 1px solid #e1e8ed;
    }

    .audio-item label {
      font-weight: 500;
      min-width: 150px;
      color: #2c3e50;
    }

    audio {
      flex: 1;
      height: 40px;
    }

    /* References */
    .references-list {
      list-style: none;
      padding: 0;
    }

    .references-list li {
      margin: 1rem 0;
      padding: 1rem;
      background: white;
      border-radius: 6px;
      border: 1px solid #e1e8ed;
    }

    .references-list a {
      color: #2a5298;
      text-decoration: none;
      font-weight: 500;
    }

    .references-list a:hover {
      text-decoration: underline;
    }

    /* Status indicators */
    .status {
      display: inline-block;
      padding: 0.3rem 0.8rem;
      border-radius: 15px;
      font-size: 0.85rem;
      font-weight: 500;
    }

    .status.in-progress {
      background: #fff3cd;
      color: #856404;
      border: 1px solid #ffeaa7;
    }

    .status.completed {
      background: #d4edda;
      color: #155724;
      border: 1px solid #c3e6cb;
    }

    .status.planned {
      background: #e2e3e5;
      color: #495057;
      border: 1px solid #d1d3d4;
    }

    /* Methodology */
    .methodology-steps {
      counter-reset: step-counter;
      list-style: none;
      padding: 0;
    }

    .methodology-steps li {
      counter-increment: step-counter;
      margin: 1.5rem 0;
      padding: 1.5rem;
      background: white;
      border-radius: 8px;
      border: 1px solid #e1e8ed;
      position: relative;
      padding-left: 4rem;
    }

    .methodology-steps li::before {
      content: counter(step-counter);
      position: absolute;
      left: 1.5rem;
      top: 1.5rem;
      background: #2a5298;
      color: white;
      width: 30px;
      height: 30px;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 600;
      font-size: 0.9rem;
    }

    .methodology-steps h4 {
      margin: 0 0 0.5rem 0;
      color: #2c3e50;
      font-size: 1.1rem;
    }

    /* Future Work */
    .future-goals {
      list-style: none;
      padding: 0;
    }

    .future-goals li {
      margin: 1rem 0;
      padding: 1rem;
      background: #f8f9fa;
      border-radius: 6px;
      border-left: 4px solid #28a745;
      position: relative;
      padding-left: 3rem;
    }

    .future-goals li::before {
      content: "→";
      position: absolute;
      left: 1rem;
      color: #28a745;
      font-weight: bold;
      font-size: 1.2rem;
    }

    /* Pipeline highlight */
    .pipeline-highlight {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white;
      padding: 2rem;
      border-radius: 8px;
      margin: 2rem 0;
    }

    .pipeline-highlight h3 {
      color: white;
      margin-top: 0;
    }

    /* Responsive */
    @media (max-width: 768px) {
      .container {
        padding: 0 1rem;
      }
      
      .header h1 {
        font-size: 2rem;
      }
      
      .nav-links {
        flex-direction: column;
        gap: 0.5rem;
        align-items: center;
      }
      
      .grid {
        grid-template-columns: 1fr;
      }
      
      .comparison-table {
        font-size: 0.8rem;
      }
      
      .audio-item {
        flex-direction: column;
        align-items: stretch;
      }
      
      .audio-item label {
        min-width: auto;
      }
    }
  </style>
</head>
<body>
  <header class="header">
    <div class="container">
      <h1>Sanskrit Speech-to-Text Translation System</h1>
      <p class="subtitle">Advanced real-time pipeline for Sanskrit audio processing using DeepFilterNet, Faster Whisper, and specialized text-to-speech synthesis</p>
      <div class="meta">
        Research Project • Real-time Processing • Sanskrit Language Technology
      </div>
    </div>
  </header>

  <nav class="nav">
    <div class="container">
      <div class="nav-container">
        <ul class="nav-links">
          <li><a href="#abstract">Abstract</a></li>
          <li><a href="#methodology">Methodology</a></li>
          <li><a href="#results">Results</a></li>
          <li><a href="#implementation">Implementation</a></li>
          <li><a href="#future-work">Future Work</a></li>
          <li><a href="#references">References</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <main class="main">
    <div class="container">
      
      <section id="abstract" class="abstract">
        <h2>Abstract</h2>
        <p>This research project presents an advanced real-time pipeline for processing Sanskrit speech through automated transcription, translation, and synthesis. Our current approach integrates DeepFilterNet for noise reduction, Faster Whisper Large-v3 for real-time speech recognition, Gemini API for intelligent text correction, and specialized Sanskrit TTS synthesis. The system is designed to handle Sanskrit linguistic complexities while maintaining real-time performance capabilities.</p>
        <p>The pipeline addresses unique challenges in Sanskrit speech processing by implementing state-of-the-art noise filtering and leveraging large language models for contextual correction of transcription errors. This work contributes to the development of practical Sanskrit language technology tools for education, research, and cultural preservation.</p>
      </section>

      <section id="methodology" class="section">
        <h2>Current Methodology</h2>
        
        <div class="pipeline-highlight">
          <h3>Real-time Processing Pipeline</h3>
          <p>Our current approach focuses on real-time processing capabilities with enhanced accuracy through multi-stage correction and specialized Sanskrit synthesis.</p>
        </div>

        <div class="grid">
          <div class="card">
            <h3>Noise Reduction</h3>
            <p>DeepFilterNet provides real-time noise suppression specifically optimized for speech clarity and processing efficiency.</p>
            <span class="status completed">Implemented</span>
          </div>
          
          <div class="card">
            <h3>Speech Recognition</h3>
            <p>Faster Whisper Large-v3 model enables real-time transcription with improved Sanskrit language support.</p>
            <span class="status completed">Implemented</span>
          </div>
          
          <div class="card">
            <h3>Text Correction</h3>
            <p>Gemini API provides intelligent post-processing correction for Sanskrit transcription accuracy.</p>
            <span class="status completed">Implemented</span>
          </div>

          <div class="card">
            <h3>Sanskrit TTS</h3>
            <p>Specialized Sanskrit text-to-speech using sanskrit-tts package with future Coqui xTTS-v2 Hindi fine-tuning.</p>
            <span class="status in-progress">In Development</span>
          </div>
        </div>

        <h3>Processing Pipeline</h3>
        <ol class="methodology-steps">
          <li>
            <h4>Audio Preprocessing</h4>
            <p>DeepFilterNet performs real-time noise reduction and speech enhancement, removing background noise while preserving Sanskrit phonetic characteristics essential for accurate recognition.</p>
          </li>
          <li>
            <h4>Real-time Speech Recognition</h4>
            <p>Faster Whisper Large-v3 model processes the filtered audio stream, providing low-latency transcription with improved Sanskrit language understanding compared to standard Whisper models.</p>
          </li>
          <li>
            <h4>Intelligent Text Correction</h4>
            <p>Gemini API analyzes the transcribed text for Sanskrit linguistic accuracy, correcting common ASR errors and ensuring proper Sanskrit grammar and vocabulary usage.</p>
          </li>
          <li>
            <h4>Sanskrit Speech Synthesis</h4>
            <p>Current implementation uses sanskrit-tts package for generating Sanskrit audio output, with ongoing development of Coqui xTTS-v2 fine-tuned on Hindi voice models for improved naturalness.</p>
          </li>
        </ol>
      </section>

      <section id="results" class="section">
        <h2>Performance Analysis</h2>
        
        <div class="results-container">
          <h3>Pipeline Performance Evaluation</h3>
          <div class="sanskrit-verse">
            यदा यदा हि धर्मस्य ग्लानिर्भवति भारत
          </div>
          <p><em>Bhagavad Gita, Chapter 4, Verse 7 - Classical Sanskrit verse used for system evaluation</em></p>

          <div class="audio-controls">
            <div class="audio-item">

            </div>
          </div>

          <h3>Processing Pipeline Comparison</h3>
          <table class="comparison-table">
            <thead>
              <tr>
                <th>Processing Stage</th>
                <th>Output Quality</th>
                <th>Real-time Performance</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>DeepFilterNet Filtering</td>
                <td>Excellent noise reduction with preserved speech clarity</td>
                <td>Sub-100ms latency for real-time processing</td>

                <td>Sanskrit TTS</td>
                <td>Functional Sanskrit pronunciation</td>
                <td>Moderate quality, planned improvements with xTTS-v2</td>
              </tr>
            </tbody>
          </table>

          <h3>Key Improvements</h3>

          <p><strong>Scalability:</strong> The modular design allows for easy replacement and upgrading of individual components as better models become available.</p>
        </div>
      </section>

      <section id="implementation" class="section">
        <h2>Implementation Details</h2>
        
        <div class="grid">
          <div class="card">
            <h3>Repository Structure</h3>
            <ul class="file-list">
              <li><a href="realtime_pipeline.ipynb" target="_blank">realtime_pipeline.ipynb</a> - Main real-time processing pipeline</li>
              <li><a href="deepfilter_preprocessing.ipynb" target="_blank">deepfilter_preprocessing.ipynb</a> - DeepFilterNet integration and testing</li>
              <li>audio/ - Test datasets and processed audio samples</li>

              <li>README.md - Complete setup and usage documentation</li>
            </ul>
          </div>

          <div class="card">
            <h3>Current Technical Stack</h3>
            <div class="code-block">
# Core Dependencies
- DeepFilterNet (Real-time noise reduction)
- Faster Whisper Large-v3 (Real-time ASR)
- Google Gemini API (Text correction)
- sanskrit-tts (Sanskrit text-to-speech)
- Coqui xTTS-v2 (Planned Hindi fine-tuning)

# Key Features
- Real-time processing capability
- Sanskrit-specific language corrections
- Modular pipeline architecture
- Streaming audio support
            </div>
          </div>
        </div>

        <h3>Sanskrit TTS Implementation</h3>
        <div class="code-block">
# Current TTS Solution
Repository: https://github.com/SameeraMurthy/sanskrit-tts.git
- Node.js package for Sanskrit pronunciation
- Phonetic mapping for Sanskrit characters
- Audio generation for Sanskrit text

# Planned Enhancement
- Coqui xTTS-v2 fine-tuning on Hindi voices
- Improved naturalness and pronunciation
- Better Sanskrit phonetic handling
        </div>

        <h3>Installation and Usage</h3>
        <div class="code-block">
git clone https://github.com/Rstar-910/SamskritaBharati
cd SamskritaBharati
pip install -r requirements.txt

# Install sanskrit-tts
git clone https://github.com/SameeraMurthy/sanskrit-tts.git
cd sanskrit-tts
npm install
        </div>
      </section>

      <section id="future-work" class="section">
        <h2>Future Development</h2>
        
        <ul class="future-goals">
          <li><strong>Coqui xTTS-v2 Integration:</strong> Fine-tune xTTS-v2 model on Hindi voice datasets to improve Sanskrit TTS naturalness and pronunciation accuracy.</li>
          <li><strong>Real-time Optimization:</strong> Further reduce processing latency through model optimization and hardware acceleration for mobile and edge deployment.</li>
          <li><strong>Sanskrit-specific ASR Fine-tuning:</strong> Fine-tune Faster Whisper on Sanskrit-specific datasets to improve phonetic recognition accuracy.</li>
          <li><strong>Voice Cloning Capabilities:</strong> Implement personalized voice synthesis for specific Sanskrit speakers or traditional recitation styles.</li>

        </ul>
      </section>

      <section id="references" class="section">
        <h2>References & Resources</h2>
        
        <ul class="references-list">
          <li>
            <a href="https://github.com/Rikorose/DeepFilterNet" target="_blank">Schröter, H., et al. (2022). DeepFilterNet: A Low Complexity Speech Enhancement Framework for Full-Band Audio. ICASSP 2022.</a>
          </li>
          <li>
            <a href="https://github.com/guillaumekln/faster-whisper" target="_blank">Kln, G. (2023). Faster Whisper: Faster implementation of OpenAI's Whisper model using CTranslate2.</a>
          </li>
          <li>
            <a href="https://github.com/SameeraMurthy/sanskrit-tts" target="_blank">Murthy, S. (2023). Sanskrit TTS: A Node.js package for Sanskrit text-to-speech synthesis.</a>
          </li>
          <li>
            <a href="https://github.com/coqui-ai/TTS" target="_blank">Coqui TTS Team. (2023). Coqui xTTS-v2: Multilingual Text-to-Speech with Voice Cloning.</a>
          </li>
          <li>
            <a href="https://ai.google.dev/gemini-api" target="_blank">Google DeepMind. (2023). Gemini API: Large Language Model for Text Generation and Analysis.</a>
          </li>
        </ul>
      </section>

    </div>
  </main>
</body>
</html>
