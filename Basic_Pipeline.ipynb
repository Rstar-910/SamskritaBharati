{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAxnN6QiE5Ef",
        "outputId": "3df395ed-6139-4b48-f866-aed7f0096181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4umocJga5Gfx",
        "outputId": "ef5a5016-4807-49cf-d941-7a5072250c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.171.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.4.26)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5db7c476-dc61-4910-a6be-d731cee35163\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5db7c476-dc61-4910-a6be-d731cee35163\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving vocals (2).wav to vocals (2).wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanskrit Transcription:\n",
            "  Yadāya Dādi Dharmassya, dlaanir bhārtībārta.\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper google-generativeai torchaudio gTTS\n",
        "\n",
        "import whisper\n",
        "import torchaudio\n",
        "import google.generativeai as genai\n",
        "import IPython.display as ipd\n",
        "from gtts import gTTS\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(API_KEY)\n",
        "\n",
        "asr_model = whisper.load_model(\"base\")\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "waveform, sr = torchaudio.load(filename)\n",
        "\n",
        "if sr != 16000:\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
        "    waveform = resampler(waveform)\n",
        "    sr = 16000\n",
        "\n",
        "clean_path = \"cleaned.wav\"\n",
        "torchaudio.save(clean_path, waveform, sr)\n",
        "\n",
        "result = asr_model.transcribe(clean_path, language='sa')\n",
        "sanskrit_text = result[\"text\"]\n",
        "print(\"Sanskrit Transcription:\\n\", sanskrit_text)\n",
        "\n",
        "GEMINI_API_KEY = api_key\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "target_language=input(\"Enter language you want to convert to: \")\n",
        "prompt = f\"Translate the following Sanskrit sentence to {target_language}. Only return the translation, with no explanation or additional text:\\n\\n{sanskrit_text}\"\n",
        "response = model.generate_content(prompt)\n",
        "conwerted = response.text\n",
        "print(\"\\nTranslation:\\n\", conwerted)\n",
        "tts = gTTS(conwerted)\n",
        "tts.save(\"output.mp3\")\n",
        "ipd.display(ipd.Audio(\"output.mp3\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Oc6izDj276Ob",
        "outputId": "b71ab78b-1fef-422f-d74a-8b34c9227209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-979ec3cc-79b0-4c8b-9920-b2f001dbb208\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-979ec3cc-79b0-4c8b-9920-b2f001dbb208\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving ttsMP3.com_VoiceText_2025-6-14_8-35-32.mp3 to ttsMP3.com_VoiceText_2025-6-14_8-35-32 (2).mp3\n",
            "Transcription:\n",
            "  Hello\n",
            "Enter language you want to convert to: Sanskrit\n",
            "\n",
            "Translation:\n",
            " नमस्ते।\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install dotenv\n",
        "\n",
        "import whisper\n",
        "import torchaudio\n",
        "import google.generativeai as genai\n",
        "import IPython.display as ipd\n",
        "from gtts import gTTS\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(API_KEY)\n",
        "\n",
        "asr_model = whisper.load_model(\"base\")\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "waveform, sr = torchaudio.load(filename)\n",
        "\n",
        "if sr != 16000:\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
        "    waveform = resampler(waveform)\n",
        "    sr = 16000\n",
        "\n",
        "clean_path = \"cleaned.wav\"\n",
        "torchaudio.save(clean_path, waveform, sr)\n",
        "\n",
        "result = asr_model.transcribe(clean_path)\n",
        "spoken_text = result[\"text\"]\n",
        "print(\"Transcription:\\n\", spoken_text)\n",
        "\n",
        "GEMINI_API_KEY = api_key\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "target_language=input(\"Enter language you want to convert to: \")\n",
        "prompt = f\"Translate the following given sentence to {target_language}. Only return the translation, with no explanation or additional text:\\n\\n{spoken_text}\"\n",
        "response = model.generate_content(prompt)\n",
        "conwerted = response.text\n",
        "print(\"\\nTranslation:\\n\", conwerted)\n",
        "tts = gTTS(conwerted)\n",
        "tts.save(\"output.mp3\")\n",
        "ipd.display(ipd.Audio(\"output.mp3\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6OJIEo-hLSZ"
      },
      "source": [
        "cd ../../.."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}