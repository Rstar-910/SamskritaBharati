{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85mGs4D1InGG"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import tempfile\n",
        "import os\n",
        "import shutil\n",
        "from df.enhance import enhance, init_df, load_audio, save_audio\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import torch\n",
        "from faster_whisper import WhisperModel\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, df_state, _ = init_df()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
        "\n",
        "print(f\"✅ Using device: {device}\")"
      ],
      "metadata": {
        "id": "RupsBSsMI7Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr_model = WhisperModel(\"large-v3\", device=device, compute_type=compute_type)"
      ],
      "metadata": {
        "id": "t9J5o_OuI-A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "if not gemini_key:\n",
        "    raise ValueError(\"❌ GEMINI_API_KEY not found in environment variables.\")\n",
        "genai.configure(api_key=gemini_key)"
      ],
      "metadata": {
        "id": "FTSdZrBKI_eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_sanskrit_text(raw_text: str) -> str:\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
        "    prompt = (\n",
        "        \"You are an expert Sanskrit linguist. \"\n",
        "        \"Please return only the grammatically correct Sanskrit version of the given text. \"\n",
        "        \"Do not provide translations, explanations, markdown, or formatting — only the corrected Sanskrit text, in plain text.\\n\\n\"\n",
        "        f\"Input: {raw_text}\"\n",
        "    )\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "5g-vK9LGIvbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_pipeline(audio_file):\n",
        "    audio, _ = load_audio(audio_file, sr=df_state.sr())\n",
        "    denoised_dir = tempfile.mkdtemp(prefix=\"denoised_\")\n",
        "    enhanced_path = os.path.join(denoised_dir, \"enhanced.wav\")\n",
        "    enhanced = enhance(model, df_state, audio)\n",
        "    save_audio(enhanced_path, enhanced, df_state.sr())\n",
        "    if not os.path.isfile(enhanced_path):\n",
        "        raise FileNotFoundError(f\"❌ Denoised file not found at {enhanced_path}\")\n",
        "    segments, _ = asr_model.transcribe(enhanced_path, language=\"sa\")\n",
        "    raw_transcription = \" \".join([s.text for s in segments])\n",
        "\n",
        "    corrected_text = correct_sanskrit_text(raw_transcription)\n",
        "\n",
        "    return raw_transcription, corrected_text"
      ],
      "metadata": {
        "id": "lQeUTMcsIxVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}